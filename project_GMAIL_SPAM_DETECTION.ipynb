{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project-GMAIL_SPAM_DETECTION",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOztNvE6qYAGwDrg0NGRj21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DHTALAN/Gmail_Spam_Detection/blob/main/project_GMAIL_SPAM_DETECTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following project is on Gmail psam detection . The project consisted of 5 steps. importing dataset , Preprocessing data , Vectorization, Training and Classification and  model evaluation. In the end we printed accuracy by Classification using Linear SVC class from sklearn library.\n",
        "\n",
        "\n",
        "MADE BY - Dhruv Talan \n",
        "\n",
        "         \n",
        "     "
      ],
      "metadata": {
        "id": "eq9tzaPwSb1_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnrYVMoHgVrq"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5cp6Quv417j"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7fHFt9646ze"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWjDqUpj5G2Z"
      },
      "source": [
        "#loading dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDARA14Z5-sy"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkmFRky6E40"
      },
      "source": [
        "dt=pd.read_csv(\"SPAM.csv\",encoding= 'Windows-1252')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylvoka5o8NPC"
      },
      "source": [
        "import chardet\n",
        "with open(\"SPAM.csv\",'rb')as rawdata:\n",
        "  result=chardet.detect(rawdata.read(100000))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6l7IiV19p3r"
      },
      "source": [
        "dt.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDROMZlT99iE"
      },
      "source": [
        "dt['SPAM']=dt['type'].map({'spam' :1, 'ham': 0}).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUM6VGkH-7v6"
      },
      "source": [
        "dt.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcW2QMNdCzAe"
      },
      "source": [
        "print(\"COLUMS IN THE GIVEN DATA: \")\n",
        "for col in dt.columns: \n",
        "    print(col) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QhXOb082HMD"
      },
      "source": [
        "t=len(dt['type'])\n",
        "print(\"NO OF ROWS IN REVIEW COLUMN:\",t)\n",
        "t=len(dt['text'])\n",
        "print(\"NO OF ROWS IN liked COLUMN:\",t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co3wMNU-E8su"
      },
      "source": [
        "#tokenisation !!\n",
        "dt['text'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN_ZxSBWFYDE"
      },
      "source": [
        "def tokenizer(text):\n",
        "  return text.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw5W2H4OFnrE"
      },
      "source": [
        "dt['text']=dt['text'].apply(tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVJxEn1RF-Iu"
      },
      "source": [
        "dt['text'][4]  #using this to keep a check on data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl3zV0_3JmpS"
      },
      "source": [
        "#stemming\n",
        "dt['text'][4]#before"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDsA3kqJwYA"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "porter=SnowballStemmer(\"english\", ignore_stopwords= False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4InhNEJ_g6"
      },
      "source": [
        "def stemit(text):\n",
        "  return[porter.stem(word) for word in text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDa4ZPBf_jI"
      },
      "source": [
        "dt['text']=dt['text'].apply(stemit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGAUFYzmgd3E"
      },
      "source": [
        "dt['text'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9GEQlerg71z"
      },
      "source": [
        "#lemmitisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vM8dqNVhD0M"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lem=WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3hkZpeuhbiH"
      },
      "source": [
        "def lemit(text):\n",
        " return [lem.lemmatize(word ,pos = 'a') for word in text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gy5l34xh7bt"
      },
      "source": [
        "dt['text']=dt['text'].apply(lemit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkkONXU8iW8B"
      },
      "source": [
        "dt['text'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg0TPLQAjanu"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNm3bylenOe5"
      },
      "source": [
        "def stp_it(text):\n",
        "  review=[word for word in text if not word in stop_words]\n",
        "  return review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zGKLPPXn1no"
      },
      "source": [
        "dt['text']=dt['text'].apply(stp_it)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPcOEzen89E"
      },
      "source": [
        "dt['text'][4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEvkgUTkoH3F"
      },
      "source": [
        "dt.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBk_SH5JoTlb"
      },
      "source": [
        "dt['text']=dt['text'].apply(' '.join)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5qlMzrdopcF"
      },
      "source": [
        "dt.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SKl51ssot3D"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer()\n",
        "y=dt.SPAM.values  \n",
        "x=tfidf.fit_transform(dt['text']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS_WOwX2x0Lg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_text,y_train,y_text=train_test_split(x,y,random_state=1 ,test_size=0.2,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC  #predicting accuracy using LinearSVC class\n",
        "linear_svc = LinearSVC(random_state=0)\n",
        "linear_svc.fit(x_train, y_train)\n",
        "y_pred = linear_svc.predict(x_text)\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_linear_svc =accuracy_score(y_pred, y_text) * 100\n",
        "print(\"accuracy:\",acc_linear_svc)"
      ],
      "metadata": {
        "id": "vmVZro2_TbHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}